{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "%matplotlib\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablin = pd.read_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Modelo evolución precios\\Datos - copia - Marta\\tablin_regresion_lineal2.csv', \n",
    "                    sep=';', engine=\"python\", decimal=',', encoding=\"latin1\")   #14.000 rows aprox\n",
    "#Tabla que viene de la regresión lineal e incluye las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_detalle = pd.read_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Proyecto\\Datos\\data_detalle_actualizado.csv', \n",
    "                   sep=';', encoding=\"latin1\", engine=\"python\", decimal=',')   #150.000 rows aprox\n",
    "#Tabla que contiene muchos detalles de algunas viviendas (vs. oracle_to_test_model_baseline_XML.csv, que tiene menos detalle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tasadoras = pd.read_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Proyecto\\Datos\\comparacion_tasadoras\\Compraracion_tasadoras.csv', \n",
    "                   sep=';', encoding=\"latin1\", engine=\"python\", decimal=',')\n",
    "#Tabla externa que viene de las tasadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_XML_OSM = pd.read_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Proyecto\\Datos\\data_detalle_actualizado_OSM_sin_duplicados.csv', \n",
    "                   sep=';', engine=\"python\", decimal=',', encoding='latin1')\n",
    "# Tabla que viene del script de creación variable OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fa03eb629a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Modelo evolución precios\\Pickles\\dict_pc.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdict_pc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "#with open(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Modelo evolución precios\\Pickles\\dict_pc.pickle', 'rb') as file:\n",
    "   # dict_pc = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_detalle = data_detalle[data_detalle['SUPERF_ADOPTADA']>1]\n",
    "data_detalle['Precio m2'] = data_detalle.loc[:, ['IMPTOTAL', 'SUPERF_ADOPTADA']].apply(lambda s: s[0]/s[1], axis=1)\n",
    "data_detalle['Index'] = data_detalle.index   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred= pd.merge(data_detalle, tablin, on=['Fecha', 'Municipio'], how='left')\n",
    "data_pred = data_pred.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates = {}\n",
    "iter_ = 0\n",
    "for year in range(2005,2019):\n",
    "    for month in ['01','04','07','10']:\n",
    "        for day in ['01']:\n",
    "            dates[day+'/'+month+'/'+str(year)] = iter_\n",
    "            iter_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred['Fecha_num'] = data_pred['Fecha'].map(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_index = data_pred.loc[:,['MATRICULA','Fecha_num']].groupby('MATRICULA').idxmax()   #agrupamos por matrícula (la fecha más posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_pred.loc[data_pred_index['Fecha_num']]   #filtramos y nos quedamos sin duplicados de la misma vivienda con distinta fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recodificar\n",
    "data_pred= data_pred.replace('SI', '1')\n",
    "data_pred= data_pred.replace('NO', '0')\n",
    "data_pred= data_pred.replace('LIBRE', 'Libre' )\n",
    "data_pred= data_pred.replace('ESPECIAL', 'Especial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con regresión lineal y sin actualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2755814066989645"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred['Predict'] = data_pred.loc[:, ['SUPERF_ADOPTADA', 'linear_regression']].apply(lambda s: s[0]*s[1], axis=1)\n",
    "data_pred['Diferencia'] = data_pred.loc[:, ['IMPTOTAL', 'Predict']].apply(lambda s: abs(s[0]-s[1]), axis=1) #imptotal - predicción = diferencia\n",
    "#Parte del coste no explicada por la regresión lineal\n",
    "data_pred['Porcentaje'] = data_pred.loc[:, ['Diferencia', 'IMPTOTAL']].apply(lambda s: s[0]/s[1], axis=1)\n",
    "#Porcentaje de la diferencia (porcentaje no explicado por la regresión lineal)\n",
    "data_pred['Porcentaje'].mean() #MAPE: media de la variación porcentual . Indica que nuestras predicciones tienen una variación del 28%. Ahora del 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred['Year'] = data_pred.Fecha.apply(lambda s: s[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_pred.drop(columns=['Predict', 'Diferencia', 'Porcentaje', 'parque_cat.1', 'tasa_cat.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar duplicados y nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_pred.drop_duplicates()\n",
    "data_pred= data_pred.dropna(subset=['Provincia']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar y hacer un merge para obtener todas las variables (código postal, OSM, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_pc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8d75c0cb5405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Map postal code so it appears as a random number that identifies the actual postal code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_XML_OSM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Codigo_Postal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_XML_OSM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Municipio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_pc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_XML_OSM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_XML_OSM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCodigo_Postal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Codigo_Postal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m38297\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_XML_OSM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCodigo_Postal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_pc' is not defined"
     ]
    }
   ],
   "source": [
    "#Map postal code so it appears as a random number that identifies the actual postal code\n",
    "data_XML_OSM['Codigo_Postal'] = data_XML_OSM['Municipio'].map(dict_pc)\n",
    "data_XML_OSM.loc[data_XML_OSM.Codigo_Postal.isnull(),'Codigo_Postal'] = [38297]*sum(data_XML_OSM.Codigo_Postal.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['EDIF_LICENCIA_COD','EDIF_CALIDAD_CONSTRU_COD','EDIF_EST_CONSERVACION_COD','VIV_ORIENTACION_COD','EDIF_FECHA_CONSTRUCCION']:\n",
    "    data_pred.loc[:,col] = data_pred.loc[:,col].apply(lambda s: str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.loc[:,'EDIF_FECHA_CONSTRUCCION'] = data_pred['EDIF_FECHA_CONSTRUCCION'].apply(lambda s: (s[5:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear variables dummies \n",
    "hi= data_pred.loc[:,['UBICACION_MUNICIPIO_DESC',\n",
    "'UBICACION_ZONA_COD','UBICACION_INMUEBLE_COD','Municipio']]\n",
    "dummy = pd.get_dummies(hi)\n",
    "data_pred = pd.concat([data_pred, dummy], axis=1)\n",
    "data_pred = data_pred.drop(['UBICACION_MUNICIPIO_DESC',\n",
    "'UBICACION_ZONA_COD','UBICACION_INMUEBLE_COD','Municipio'], axis=1)\n",
    "#YA TENEMOS EL DATASET \"PRUEBA\", PREPARADO PARA MACHINE LEARNING, CON LOS MUNICIPIOS COMO DUMMIES Y EL AÑO CON UN ÍNDICE\n",
    "#HABRÍA QUE PROBAR SI SERÍA MEJOR SEGUIR HACIENDO EL LOOP POR MUNICIPIOS O DEJARLOS COMO DUMMIES\n",
    "#EDIF_FECHA_CONSTRUCCION   convertirla a numérica y así se puede introducir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred['EDIF_FECHA_CONSTRUCCION']= data_pred.loc[:,['EDIF_FECHA_CONSTRUCCION']].replace(\"\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_pred = data_pred.fillna(data_pred.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred= data_pred.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe= data_pred.merge(data_XML_OSM.loc[:,['MATRICULA','Establecimientos_OSM','Codigo_Postal']], left_on=['MATRICULA'],\n",
    "                                right_on=['MATRICULA'],\n",
    "                                left_index=True, how='inner')\n",
    "dataframe = dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De la fecha de construcción, obtener una variable de antigüedad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos la fecha de construccion a una variable de antigüedad de la vivienda\n",
    "dataframe['EDIF_FECHA_CONSTRUCCION']= dataframe['EDIF_FECHA_CONSTRUCCION'].astype(int)\n",
    "indexNames = dataframe[(dataframe['EDIF_FECHA_CONSTRUCCION'] < 1800)].index\n",
    "dataframe.drop(indexNames , inplace=True)\n",
    "dataframe['EDIF_FECHA_CONSTRUCCION']= dataframe['EDIF_FECHA_CONSTRUCCION'] - 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitar outliers y guardar la tabla final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitar outliers\n",
    "dataframe= dataframe[np.abs(dataframe['IMPTOTAL']-dataframe['IMPTOTAL'].mean()) <= (3*dataframe['IMPTOTAL'].std())] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(r'C:\\Users\\Marta\\Desktop\\Rotación 2 SBD\\BackUp_Proyecto\\Python Scripts\\Modelo evolución precios\\Datos - copia - Marta\\tabla_modelos.csv', \n",
    "                   sep=';', encoding=\"latin1\", decimal=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
